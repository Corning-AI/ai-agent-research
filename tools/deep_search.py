#!/usr/bin/env python3
"""
æ·±åº¦ GitHub æœç´¢å·¥å…·
å¢å¼ºç‰ˆæœç´¢ï¼Œæ”¯æŒæ™ºèƒ½å…³é”®è¯æ‰©å±•ã€å¤šç»´åº¦è¿‡æ»¤ã€å»é‡åˆå¹¶
"""

import subprocess
import json
import sqlite3
import time
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Set
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict


class DeepSearchEngine:
    """æ·±åº¦æœç´¢å¼•æ“"""

    def __init__(self, db_path: str = "../data/projects.db"):
        self.db_path = db_path
        self.existing_repos: Set[str] = self._load_existing_repos()

        # æ‰©å±•æœç´¢å…³é”®è¯åº“
        self.search_queries = {
            "cad": [
                # åŸºç¡€ CAD
                ("CAD python", "cad"),
                ("computer aided design", "cad"),
                ("3D modeling automation", "cad"),
                ("parametric design", "cad"),
                ("generative design", "cad"),
                ("topology optimization", "cad"),

                # æŠ€æœ¯æ ˆ
                ("OpenCASCADE python", "cad"),
                ("FreeCAD scripting", "cad"),
                ("Blender python API", "cad"),
                ("pythonOCC", "cad"),
                ("cadquery", "cad"),

                # AI ç›¸å…³
                ("AI CAD", "cad"),
                ("machine learning 3D modeling", "cad"),
                ("neural CAD", "cad"),
                ("AI 3D generation", "cad"),
                ("text to 3D model", "cad"),
                ("LLM CAD assistant", "cad"),
                ("GPT CAD automation", "cad"),

                # åº”ç”¨é¢†åŸŸ
                ("mechanical design automation", "cad"),
                ("architectural design tool", "cad"),
                ("product design software", "cad"),
                ("CAM programming", "cad"),
                ("CNC automation", "cad"),

                # æ–°å…´æ–¹å‘
                ("procedural modeling", "cad"),
                ("computational design", "cad"),
                ("algorithm design", "cad"),
                ("design optimization", "cad"),
            ],

            "circuit": [
                # åŸºç¡€ç”µè·¯
                ("circuit design", "circuit"),
                ("PCB design", "circuit"),
                ("electronic design automation", "circuit"),
                ("EDA tools", "circuit"),
                ("IC design", "circuit"),

                # ä»¿çœŸ
                ("circuit simulation", "circuit"),
                ("SPICE simulator", "circuit"),
                ("analog simulation", "circuit"),
                ("digital logic simulation", "circuit"),
                ("ngspice python", "circuit"),

                # ç¡¬ä»¶æè¿°
                ("Verilog HDL", "circuit"),
                ("VHDL design", "circuit"),
                ("hardware description language", "circuit"),
                ("RTL design", "circuit"),

                # PCB å·¥å…·
                ("KiCad automation", "circuit"),
                ("KiCad python", "circuit"),
                ("PCB router", "circuit"),
                ("PCB autorouter", "circuit"),
                ("gerber generation", "circuit"),

                # AI ç›¸å…³
                ("AI PCB routing", "circuit"),
                ("machine learning circuit", "circuit"),
                ("neural network hardware", "circuit"),
                ("AI chip design", "circuit"),
                ("ML accelerator", "circuit"),

                # æµ‹è¯•éªŒè¯
                ("circuit testing", "circuit"),
                ("hardware verification", "circuit"),
                ("formal verification", "circuit"),

                # æ–°å…´æ–¹å‘
                ("quantum circuit", "circuit"),
                ("neuromorphic hardware", "circuit"),
                ("FPGA design", "circuit"),
            ],

            "cross_domain": [
                # LaTeX + AI
                ("GPT LaTeX", "latex"),
                ("AI paper writing", "latex"),
                ("LLM academic writing", "latex"),
                ("automated LaTeX generation", "latex"),

                # CAD + LLM
                ("text to 3D", "cad"),
                ("conversational CAD", "cad"),
                ("LLM 3D modeling", "cad"),
                ("GPT CAD", "cad"),

                # Circuit + ML
                ("neural hardware design", "circuit"),
                ("AI chip", "circuit"),
                ("ML hardware accelerator", "circuit"),

                # Framework + Domain
                ("multi-agent CAD", "framework"),
                ("LLM framework design", "framework"),
                ("agent-based modeling", "framework"),
            ]
        }

    def _load_existing_repos(self) -> Set[str]:
        """åŠ è½½å·²å­˜åœ¨çš„ä»“åº“ï¼Œé¿å…é‡å¤"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT full_name FROM projects")
            repos = {row[0] for row in cursor.fetchall()}
            conn.close()
            return repos
        except:
            return set()

    def search_with_gh(self, query: str, domain: str, limit: int = 30) -> Tuple[Dict, List[Dict]]:
        """ä½¿ç”¨ GitHub CLI æœç´¢"""
        print(f"  ğŸ” æœç´¢: {query[:50]}...")

        try:
            cmd = [
                "gh", "search", "repos",
                query,
                "--limit", str(limit),
                "--sort", "stars",
                "--json", "name,owner,stargazersCount,forksCount,description,url,updatedAt,createdAt,language,license,openIssuesCount"
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)

            if result.returncode != 0:
                print(f"    âŒ æœç´¢å¤±è´¥: {result.stderr[:100]}")
                return {"query": query, "domain": domain, "count": 0}, []

            repos = json.loads(result.stdout)

            # è¿‡æ»¤å·²å­˜åœ¨çš„ä»“åº“
            new_repos = []
            for repo in repos:
                full_name = f"{repo['owner']['login']}/{repo['name']}"
                if full_name not in self.existing_repos:
                    new_repos.append(repo)
                    self.existing_repos.add(full_name)  # æ·»åŠ åˆ°é›†åˆé˜²æ­¢é‡å¤

            print(f"    âœ… æ‰¾åˆ° {len(repos)} ä¸ªé¡¹ç›®ï¼Œ{len(new_repos)} ä¸ªæ–°é¡¹ç›®")

            return {
                "query": query,
                "domain": domain,
                "count": len(new_repos),
                "total": len(repos)
            }, new_repos

        except subprocess.TimeoutExpired:
            print(f"    â±ï¸  æœç´¢è¶…æ—¶")
            return {"query": query, "domain": domain, "count": 0, "error": "timeout"}, []
        except Exception as e:
            print(f"    âŒ é”™è¯¯: {str(e)[:100]}")
            return {"query": query, "domain": domain, "count": 0, "error": str(e)}, []

    def calculate_quality_score(self, repo: Dict) -> float:
        """è®¡ç®—é¡¹ç›®è´¨é‡åˆ†æ•°ï¼ˆ0-100ï¼‰"""
        score = 0.0

        # 1. Stars (30åˆ†)
        stars = repo.get("stargazersCount", 0)
        if stars > 10000:
            score += 30
        elif stars > 1000:
            score += 20
        elif stars > 100:
            score += 10
        elif stars > 10:
            score += 5

        # 2. æ›´æ–°æ—¶é—´ (20åˆ†)
        updated = repo.get("updatedAt", "")
        if updated:
            try:
                update_date = datetime.fromisoformat(updated.replace('Z', '+00:00'))
                days_ago = (datetime.now(update_date.tzinfo) - update_date).days
                if days_ago < 30:
                    score += 20
                elif days_ago < 90:
                    score += 15
                elif days_ago < 180:
                    score += 10
                elif days_ago < 365:
                    score += 5
            except:
                pass

        # 3. Forks (15åˆ†)
        forks = repo.get("forksCount", 0)
        if forks > 1000:
            score += 15
        elif forks > 100:
            score += 10
        elif forks > 10:
            score += 5

        # 4. Issues (15åˆ†) - æœ‰é€‚é‡çš„ open issues è¯´æ˜æ´»è·ƒ
        issues = repo.get("openIssuesCount", 0)
        if 10 <= issues <= 100:
            score += 15
        elif 1 <= issues < 10:
            score += 10
        elif issues > 100:
            score += 5

        # 5. æè¿° (10åˆ†)
        if repo.get("description"):
            score += 10

        # 6. License (10åˆ†)
        license_info = repo.get("license")
        if license_info:
            license_name = license_info.get("name", "").lower() if isinstance(license_info, dict) else str(license_info).lower()
            if "mit" in license_name or "apache" in license_name or "bsd" in license_name:
                score += 10
            else:
                score += 5

        return round(score, 2)

    def save_to_database(self, repos: List[Dict], domain: str):
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        if not repos:
            return 0

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        saved_count = 0
        for repo in repos:
            try:
                owner_login = repo["owner"]["login"]
                name = repo["name"]
                full_name = f"{owner_login}/{name}"

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("SELECT COUNT(*) FROM projects WHERE full_name = ?", (full_name,))
                if cursor.fetchone()[0] > 0:
                    continue

                stars = repo.get("stargazersCount", 0)
                forks = repo.get("forksCount", 0)
                description = repo.get("description", "")
                url = repo.get("url", "")
                updated_at = repo.get("updatedAt", "")
                created_at = repo.get("createdAt", "")
                language = repo.get("language", "")

                license_name = ""
                if repo.get("license"):
                    if isinstance(repo["license"], dict):
                        license_name = repo["license"].get("name", "")
                    else:
                        license_name = repo["license"]

                # è®¡ç®—è´¨é‡åˆ†æ•°
                quality_score = self.calculate_quality_score(repo)

                cursor.execute("""
                INSERT INTO projects (
                    domain, name, full_name, owner, url, description,
                    stars, forks, main_language, license, topics,
                    created_at, last_updated, activity_score
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    domain, name, full_name, owner_login, url, description,
                    stars, forks, language, license_name, "[]",
                    created_at, updated_at, quality_score
                ))

                saved_count += 1

            except Exception as e:
                print(f"    âš ï¸  ä¿å­˜å¤±è´¥ {full_name}: {str(e)[:50]}")

        conn.commit()
        conn.close()

        return saved_count

    def parallel_deep_search(self, domains: List[str], max_workers: int = 10):
        """å¹¶è¡Œæ·±åº¦æœç´¢"""
        print(f"\n{'='*80}")
        print(f"ğŸš€ å¯åŠ¨æ·±åº¦æœç´¢å¼•æ“ - {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹")
        print(f"{'='*80}\n")

        # å‡†å¤‡æœç´¢ä»»åŠ¡
        search_tasks = []
        for domain_key in domains:
            if domain_key in self.search_queries:
                for query, domain in self.search_queries[domain_key]:
                    search_tasks.append((query, domain))

        print(f"ğŸ“Š æ€»å…± {len(search_tasks)} ä¸ªæœç´¢ä»»åŠ¡\n")

        all_results = []
        domain_stats = defaultdict(lambda: {"total": 0, "new": 0, "repos": []})

        start_time = time.time()

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {
                executor.submit(self.search_with_gh, query, domain): (query, domain)
                for query, domain in search_tasks
            }

            for future in as_completed(future_to_task):
                query, domain = future_to_task[future]
                try:
                    result, repos = future.result()
                    all_results.append(result)

                    if repos:
                        domain_stats[domain]["total"] += result.get("total", 0)
                        domain_stats[domain]["new"] += len(repos)
                        domain_stats[domain]["repos"].extend(repos)

                except Exception as e:
                    print(f"  âŒ ä»»åŠ¡å¤±è´¥: {query[:30]} - {str(e)[:50]}")

        elapsed = time.time() - start_time

        # ä¿å­˜åˆ°æ•°æ®åº“
        print(f"\n{'='*80}")
        print(f"ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
        print(f"{'='*80}\n")

        total_saved = 0
        for domain, stats in domain_stats.items():
            saved = self.save_to_database(stats["repos"], domain)
            total_saved += saved
            print(f"  {domain:12} - ä¿å­˜ {saved}/{stats['new']} ä¸ªæ–°é¡¹ç›®")

        # ç»Ÿè®¡æŠ¥å‘Š
        print(f"\n{'='*80}")
        print(f"ğŸ“ˆ æ·±åº¦æœç´¢å®Œæˆ")
        print(f"{'='*80}\n")
        print(f"  æ€»è€—æ—¶: {elapsed:.2f} ç§’")
        print(f"  æœç´¢ä»»åŠ¡: {len(search_tasks)} ä¸ª")
        print(f"  æ–°å¢é¡¹ç›®: {total_saved} ä¸ª")
        print(f"\nå„é¢†åŸŸç»Ÿè®¡:")

        for domain in sorted(domain_stats.keys()):
            stats = domain_stats[domain]
            print(f"  {domain:12} - æœç´¢åˆ° {stats['total']:3d} ä¸ªï¼Œæ–°å¢ {stats['new']:3d} ä¸ª")

        return domain_stats, total_saved


def main():
    """ä¸»å‡½æ•°"""
    engine = DeepSearchEngine()

    print("\n" + "="*80)
    print("ğŸ¯ æ·±åº¦ GitHub æœç´¢è®¡åˆ’")
    print("="*80)
    print("\né€‰æ‹©æœç´¢èŒƒå›´ï¼š")
    print("  1. CAD é¢†åŸŸæ·±åº¦æœç´¢")
    print("  2. Circuit é¢†åŸŸæ·±åº¦æœç´¢")
    print("  3. è·¨é¢†åŸŸé¡¹ç›®æœç´¢")
    print("  4. å…¨éƒ¨æ‰§è¡Œï¼ˆæ¨èï¼‰")

    choice = input("\nè¯·é€‰æ‹© (1-4, é»˜è®¤ 4): ").strip() or "4"

    domains_map = {
        "1": ["cad"],
        "2": ["circuit"],
        "3": ["cross_domain"],
        "4": ["cad", "circuit", "cross_domain"]
    }

    domains = domains_map.get(choice, ["cad", "circuit", "cross_domain"])

    print(f"\nå°†æ‰§è¡Œ: {', '.join(domains)}")
    input("\næŒ‰ Enter å¼€å§‹æœç´¢...")

    stats, total = engine.parallel_deep_search(domains, max_workers=10)

    print(f"\nâœ… æ·±åº¦æœç´¢å®Œæˆï¼æ–°å¢ {total} ä¸ªé¡¹ç›®")


if __name__ == "__main__":
    main()
